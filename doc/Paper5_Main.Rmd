---
title: "Project 4 - Paper 5 Main Script"
author: "Xuehan Liu"
date: "04/05/2017"
output: pdf_document
---

In this file, we illustrate our step-by-step procedure on the error driven online training algorithm on the nameset AKumar.txt (step0 - step3). We implement the algorithm on all name sets based on the step-by-step procedure described from step0-step3, and saved it in the "lib" folder. In step4, we report the evaluation to all namesets provided.

## Step 0: Load the packages, specify directories

```{r}
setwd("/Users/xuehan/Desktop/Spr2017-proj4-team-9/")
# here replace it with your own path or manually set it in RStudio
# to where this rmd file is located


if (!require("pacman")) install.packages("pacman")
pacman::p_load(text2vec, dplyr, qlcMatrix, kernlab, knitr)

#Create useable csv for each name set
source("../lib/data cleaner.R")
```

## Step 1: Load and process the data

```{r}
AKumar <- data.frame(scan("../data/nameset/AKumar.txt",
                          what = list(Coauthor = "", Paper = "", Journal = ""),
                          sep=">", quiet=TRUE),stringsAsFactors=FALSE)

# extract canonical author id befor "_"
  AKumar$AuthorID <- sub("_.*","", AKumar$Coauthor)
  # extract paper number under same author between "_" and first whitespace
  AKumar$PaperNO <- sub(".*_(\\w*)\\s.*", "\\1",  AKumar$Coauthor)
  # delete "<" in AKumar$Coauthor, you may need to further process the coauthor
  # term depending on the method you are using
  AKumar$Coauthor <- gsub("<","",sub("^.*?\\s","",  AKumar$Coauthor))
  # delete "<" in AKumar$Paper
  AKumar$Paper <- gsub("<","", AKumar$Paper)
  # add PaperID for furthur use, you may want to combine all the nameset files and 
  # then assign the unique ID for all the citations
   AKumar$PaperID <- rownames( AKumar)

```


## Step 2: Feature Design

As mentioned in the paper, we can use TF-IDF to collect all unique terms in each citation.  

```{r}
it_train <- itoken(AKumar$Paper, 
             preprocessor = tolower, 
             tokenizer = word_tokenizer,
             ids = AKumar$PaperID,
             # turn off progressbar because it won't look nice in rmd
             progressbar = FALSE)
vocab <- create_vocabulary(it_train, stopwords = c("a", "an", "the", "in", "on",
                                                   "at", "of", "above", "under"))

#vocab

vectorizer <- vocab_vectorizer(vocab)
dtm_train <- create_dtm(it_train, vectorizer)
dim(dtm_train)

tfidf <- TfIdf$new()
dtm_train_tfidf <- fit_transform(dtm_train, tfidf)

```


## Step 3: Implementing hierirchical clustering and training parameters 
In this section, our goal is to train the lambda on hierirchical clustering on our text file AKumar by the error driven online training method introduced in the paper5. We use the ranking perceptron to update the parameters.

```{r,warning=FALSE}
####Initialize Parameter lambda
lambda<-rep(1,nrow(dtm_train_tfidf))

#Add the Author's ID as the label column to the feature matrix for future use
dtm_train_tfidf<-cbind(dtm_train_tfidf,as.numeric(AKumar$AuthorID))


#Given the training set, we are able to generate the true clusters. 
#Based on the paper, we define true score S_star as the distance of the sum of clusterwise distance. We also define our own score function as the sum of distance of clusters that is clustered by hclust() function.


#Compute the true score S_star for the giving training data
element<-list()
S_star<-vector(length=length(unique(AKumar$AuthorID)))
for (i in 1:length(unique(AKumar$AuthorID))){
  element[[i]]<-dtm_train_tfidf[dtm_train_tfidf[,ncol(dtm_train_tfidf)]==i,]
  S_star[i]<-sum(dist(element[[i]]))/2
}
S_star<-mean(S_star)
T_star<-dtm_train_tfidf[,ncol(dtm_train_tfidf)]

K=14
k=1
lambda1 <- matrix(NA, nrow = nrow(AKumar), ncol = K)
S1 <- numeric(K)
acc <- numeric(K)
while (k<(K+1)){
  
#Implement Hierirchical Clustering 
h<-hclust(dist(dtm_train_tfidf*lambda))
#Check the result for the number of cluster equals to the number of unique authors in the dataset. 
h_result<-cutree(h,k=length(unique(AKumar$AuthorID)))

#Compute the our own score function S
S<-vector(length=length(unique(AKumar$AuthorID)))
element_s<-list()
for (i in 1:length(unique(AKumar$AuthorID))){
  element_s[[i]]<-dtm_train_tfidf[which(h_result==i),]
  S[i]<-sum(dist(element_s[[i]]))/2
}
S<-mean(S)



#Identify true author for each cluster generated by hclust() function, and assign it to each element of the cluster.

label<-dtm_train_tfidf[,ncol(dtm_train_tfidf)]
author.clust <- vector(length=length(unique(AKumar$AuthorID)))
for (i in 1:length(unique(AKumar$AuthorID))){
    author.clust[i]<-as.numeric(names(which.max(table(label[which(h_result==i)]))))
}

for (i in 1:unique(AKumar$AuthorID)){
    h_result[h_result==i]<-author.clust[i]
}
T_hat<-h_result

#Update lambda

for (i in 1:length(T_star)){
  if (T_hat[i]!=T_star[i]){
    lambda[i]<-lambda[i]-((S-S_star)/S) #!!!
  }
  else {
    lambda[i]<-lambda[i]
  }
}
lambda1[,k] <- lambda
S1[k] <- S
acc[k] <- mean(label == h_result)    
k=k+1
}

#plot(acc)
#lambda1[,K]
h_new<-hclust(dist(dtm_train_tfidf*lambda))
T_hat_overall<-cutree(h_new,k=unique(AKumar$AuthorID))

```


## Step 5: Evaluation on all dataset 

```{r,warning=FALSE}
source('../lib/evaluation_measures.R') 
source('../lib/data cleaner.R')

#performance statistics for AKumar
matching_matrix_hclust <- matching_matrix(AKumar$AuthorID,T_hat_overall) 
performance_hclust.AK <- performance_statistics(matching_matrix_hclust)
performance_hclust.AK

source('../lib/Y Chen.R') 
performance_hclust
source('../lib/KTanaka.R')
performance_hclust.KT
source('../lib/JSmith.R')
performance_hclust.JS
source('../lib/MMiller.R')
performance_hclust.MM
source('../lib/MBrown.R')
performance_hclust.MB
source('../lib/MJones.R')
performance_hclust.MJ
source('../lib/JLee.R')
performance_hclust.JL
source('../lib/JMartin.R')
performance_hclust.JM
source('../lib/JRobinson.R')
performance_hclust.JR
source('../lib/DJohnson.R')
performance_hclust.DJ
source('../lib/CChen.R')
performance_hclust.CC
source('../lib/AGupta.R')
performance_hclust.AG

#compute average of the all four performance statistics
Precision<-c(performance_hclust.AK$precision,performance_hclust$precision,performance_hclust.MB$precision,performance_hclust.KT$precision,performance_hclust.JS$precision,performance_hclust.MM$precision,performance_hclust.MJ$precision,performance_hclust.JL$precision,performance_hclust.JM$precision,performance_hclust.JR$precision,performance_hclust.DJ$precision,performance_hclust.CC$precision,performance_hclust.AG$precision)

Recall<-c(performance_hclust.AK$recall,performance_hclust$recall,performance_hclust.MB$recall,performance_hclust.KT$recall,performance_hclust.JS$recall,performance_hclust.MM$recall,performance_hclust.MJ$recall,performance_hclust.JL$recall,performance_hclust.JM$recall,performance_hclust.JR$recall,performance_hclust.DJ$recall,performance_hclust.CC$recall,performance_hclust.AG$recall)


F1<-c(performance_hclust.AK$f1,performance_hclust$f1,performance_hclust.MB$f1,performance_hclust.KT$f1,performance_hclust.JS$f1,performance_hclust.MM$f1,performance_hclust.MJ$f1,performance_hclust.JL$f1,performance_hclust.JM$f1,performance_hclust.JR$f1,performance_hclust.DJ$f1,performance_hclust.CC$f1,performance_hclust.AG$f1)



Accuracy<-F1<-c(performance_hclust.AK$accuracy,performance_hclust$accuracy,performance_hclust.MB$accuracy,performance_hclust.KT$accuracy,performance_hclust.JS$accuracy,performance_hclust.MM$accuracy,performance_hclust.MJ$accuracy,performance_hclust.JL$accuracy,performance_hclust.JM$accuracy,performance_hclust.JR$accuracy,performance_hclust.DJ$accuracy,performance_hclust.CC$accuracy,performance_hclust.AG$accuracy)

#Final Performance Summary combining all 14 namesets.
error.driven<-data.frame(Precision=mean(Precision),Recall=mean(Recall),F1=mean(F1),Accuracy=mean(Accuracy))
```